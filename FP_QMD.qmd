---
title: "QMD_FP"
author: "Naman"
format: pdf
editor: visual
---

## 

```{r}


```

```{r}
##Introduction
The New York Times state-level dataset provides a daily record of cases and deaths for each state, which allows for a data-driven exploration of how the virus spread. Since this project uses those public counts to describe broad patterns, we can focus on simple summaries that are appropriate for an introductory course. Then, the analysis begins with an overview of the dataset, which would then move to geographic comparisons and trends over time. Each team member is responsible for a distinct part of the workflow, like data cleaning or visualization. Thus, throughout the report, the team emphasizes clear documentation and ethical use of data, which allows others to re-run the analysis on the same file using our code.

## Data Provenance

In this project, we use a COVID-19 dataset from The New York Times which contains cumulative counts of cases and deaths for each state. Then, since our file covers the period from January 21, 2020 to March 23, 2023, we can get the data based on the minimum and maximum dates. Then, because the values are aggregated from health agencies, they are made available as a CSV file on GitHub, which would allow us to use it.

## FAIR and CARE Principles

For this project, the NYTimes data is consistent with FAIR principles because it is widely accessible online. Since it uses stable identifiers like state names and follows a table structure, this would allow it to be combined with other data like population estimates for analysis. Then, the data is also findable and reusable because it comes from a good publisher with clear updates, which allows it to support questions about patterns in the pandemic. At the same time, it is important to look at CARE principles by realizing that COVID results show differences across communities. Then, since we want to avoid blaming specific states, we should focus on context like healthcare access and health differences. Thus, when looking at results, the team will frame the analysis to respect communities, which avoids claiming too much and shows how clear data can help public health responses.
```

```{r}
# code header: primary = Naman, reviewer = Riya
# Style guide: Tidyverse
library(knitr)
library(tidyverse)
library(lubridate)

# Read in NYTimes US states data 
us_states <- read_csv(
  "C:/Users/naman/Downloads/us-states.csv",
  show_col_types = FALSE
)

# Basic cleaning / type fixes
covid_states <- us_states |>
  mutate(
    date  = as.Date(date, format = "%m/%d/%Y"),
    state = as.factor(state)
  )
# find the last date in the cleaned dataset
last_date <- max(covid_states$date, na.rm = TRUE)

# create one-row-per-state summary
dataset_overview <- covid_states |>
  group_by(state) |>
  summarise(
    total_cases_latest = max(cases, na.rm = TRUE),
    total_deaths_latest = max(deaths, na.rm = TRUE),
    first_reporting_date = min(date, na.rm = TRUE),
    last_reporting_date = max(date, na.rm = TRUE),
    .groups = "drop"
  ) |>
  arrange(desc(total_cases_latest))

# show top 10 states by total cases (can remove slice_head to show all)
dataset_overview |>
  slice_head(n = 10) |>
  kable(
    caption = "Table 1: Overview of NYTimes state-level COVID-19 data, showing the latest cumulative cases and deaths and the first/last reporting dates for the ten states with the largest total case counts."
  )
View(dataset_overview)
```
